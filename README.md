# ctc-lid

A CTC-training based model for language identification.
--

对于语种识别任务，可以用语音和音素序列标注先训练一个CTC对齐的音素解码模型，然后调整模型结构，进行语种识别的fine-tuning训练。对比直接采用声学特征去训练语种识别的系统，有明显的性能提升。

### 运行环境
  ```
  python 3.6+
  pytorch v1.5.0
  ```

### 特征提取与VAD

 用kaldi提取fbank特征，提取mfcc特征并计算VAD，然后去除fbank特征中的静音帧。当然也可以用torchaudio提取声学特征。
 
### 模型结构

以LSTM层提取帧级别的特征，经过含非线性层的前向网络（FFN)得到bottleneck特征，输出层分为CTC音素预测与语种类别预测。

### 语种识别结果对比

  在某个不公开的方言识别任务上，共有10个方言语种，时长从2秒到几十秒不等，音频录制的信道与环境有较大差异。对比是否开启CTC预训练的语种识别结果：
  
|ID| Model |Acc | 
|---|--------- | --- |
|1| BiLSTM\_H1024\_L2 + FFN\_BN256 + 无CTC预训练 | 79.34%| 
|2| BiLSTM\_H1024\_L2 + FFN\_BN256 + CTC预训练 | **83.68%** |
|3| ResNet18 + BiLSTM\_H512\_L1 + FFN\_BN256 + CTC预训练 | **85.38%** |

### 分析与结论
- 音素标注的准确性很重要。如果语音测试集没有音素标注序列，可以考虑训练一个相近语言的语音识别音素解码器，对语种语音进行音素标注。
- 当音频的录制信道与环境有较大差异时，直接训练端到端的语种识别系统，可能会受到信道和环境噪音的严重影响。而某个发音音素或音素序列会出现于不同信道和背景下的语音中，预训练CTC对齐的音素解码器，使得模型真正地学习语种语言的信息，较好地抑制了信道和环境噪音的影响。
- ResNet等卷积类网络，在处理帧级别的特征上对比LSTM网络有较大优势。另一方面，优于语音帧数一般比对应的音素序列长度多很多，卷积类网络可以在时序（即长度）的维度上降维，一般可将CNN输出的长度降到输入序列的四分之一，对CTC预训练和语种训练都有较大帮助。


### 其他优化方向

 - 数据增广
     - 可以对语音进行变速处理，一般有0.9倍速和1.1倍速，数据即可增广为原来的3倍。语音变速工具可使用sox。
     - 适当加噪音。
 - 精简优化测试时的前向计算过程，去掉不必要的CTC相关的计算步骤。
